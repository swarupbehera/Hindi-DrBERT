# Hindi-DrBERT
Repository for the paper "Hindi-DrBERT: A Robust Pre-trained Model in Hindi for Biomedical and Clinical domains."

In recent years, pre-trained language models (PLMs) have demonstrated exceptional performance across a wide range of natural language processing (NLP) tasks. While the initial models were trained on general domain data, specialized models have emerged to effectively address specific domains. This paper introduces an original study of PLMs in the medical domain, with a particular focus on the Hindi language. For the first time, we compare the performance of PLMs trained on both publicly available web data and private data from healthcare establishments. We also evaluate different learning strategies for a set of biomedical tasks. Notably, we showcase the capability of utilizing existing biomedical PLMs in a foreign language by further pre-training them on our specific data. Finally, we present Hindi-DrBERT as the first specialized PLMs for the biomedical field in Hindi, along with the largest collection of medical data available under a free license, which was utilized to train these models.
